{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de funcionamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funcinamiento Driver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conexi√≥n exitosa a SQL Server\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn_str = \"DRIVER={ODBC Driver 17 for SQL Server};SERVER=localhost;DATABASE=master;Trusted_Connection=yes\"\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    print(\"‚úÖ Conexi√≥n exitosa a SQL Server\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\" Error de conexi√≥n: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importacion de las Consultas SQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Directorio actual: c:\\Users\\marti\\gd_clv-2\\data_migration\n",
      " Ruta esperada para queries: c:\\Users\\marti\\gd_clv-2\\data_migration\\queries\n",
      " Carpeta encontrada correctamente.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = os.getcwd()  # Devuelve el directorio actual donde se ejecuta el script\n",
    "print(f\" Directorio actual: {BASE_DIR}\")\n",
    "\n",
    "#Construir la ruta de la carpeta `queries`\n",
    "SQL_QUERIES_PATH = os.path.join(BASE_DIR, \"queries\")\n",
    "print(f\" Ruta esperada para queries: {SQL_QUERIES_PATH}\")\n",
    "\n",
    "#  Verificar si encuentra la cerpta de las queries\n",
    "if os.path.exists(SQL_QUERIES_PATH):\n",
    "    print(\" Carpeta encontrada correctamente.\")\n",
    "else:\n",
    "    print(\" ERROR: La carpeta no existe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÇ Archivos SQL encontrados: ['cliente.sql', 'fact_table.sql', 'geog.sql', 'prod.sql', 'tiempo.sql']\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(SQL_QUERIES_PATH):\n",
    "    sql_files = [f for f in os.listdir(SQL_QUERIES_PATH) if f.endswith(\".sql\")]\n",
    "    print(f\"üóÇ Archivos SQL encontrados: {sql_files}\")\n",
    "else:\n",
    "    print(\"‚ùå ERROR: No se encontr√≥ la carpeta `queries/`.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Encontrados 5 archivos SQL.\n",
      "1.Conectando a Azure SQL\n",
      "2.Conectando a SQL Server Local\n",
      " Procesando archivo: cliente.sql\n",
      " Ejecutando consulta en Azure SQL para cliente.sql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17728\\1569642319.py:53: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn_azure)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Datos extra√≠dos: 44053 filas.\n",
      " Tabla cliente eliminada si exist√≠a.\n",
      "‚úÖ Tabla cliente creada en SQL Server Local.\n",
      " 44053 filas insertadas en cliente.\n",
      " Procesando archivo: fact_table.sql\n",
      " Ejecutando consulta en Azure SQL para fact_table.sql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17728\\1569642319.py:53: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn_azure)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Datos extra√≠dos: 58049 filas.\n",
      " Tabla fact_table eliminada si exist√≠a.\n",
      "‚úÖ Tabla fact_table creada en SQL Server Local.\n",
      " 58049 filas insertadas en fact_table.\n",
      " Procesando archivo: geog.sql\n",
      " Ejecutando consulta en Azure SQL para geog.sql\n",
      " Datos extra√≠dos: 12 filas.\n",
      " Tabla geog eliminada si exist√≠a.\n",
      "‚úÖ Tabla geog creada en SQL Server Local.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17728\\1569642319.py:53: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn_azure)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12 filas insertadas en geog.\n",
      " Procesando archivo: prod.sql\n",
      " Ejecutando consulta en Azure SQL para prod.sql\n",
      " Datos extra√≠dos: 404 filas.\n",
      " Tabla prod eliminada si exist√≠a.\n",
      "‚úÖ Tabla prod creada en SQL Server Local.\n",
      " 404 filas insertadas en prod.\n",
      " Procesando archivo: tiempo.sql\n",
      " Ejecutando consulta en Azure SQL para tiempo.sql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17728\\1569642319.py:53: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn_azure)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17728\\1569642319.py:53: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn_azure)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Datos extra√≠dos: 3652 filas.\n",
      " Tabla tiempo eliminada si exist√≠a.\n",
      "‚úÖ Tabla tiempo creada en SQL Server Local.\n",
      " 3652 filas insertadas en tiempo.\n",
      "\n",
      " ¬°Proceso completado!\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Rutas de conexi√≥n Azure\n",
    "AZURE_SERVER = 'uaxmathfis.database.windows.net'\n",
    "AZURE_DATABASE = 'usecases'\n",
    "AZURE_DRIVER = '{ODBC Driver 17 for SQL Server}'\n",
    "#Conexi√≥n Azure\n",
    "azure_conn_str = f\"DRIVER={AZURE_DRIVER};SERVER={AZURE_SERVER};DATABASE={AZURE_DATABASE};Authentication=ActiveDirectoryInteractive\"\n",
    "\n",
    "# Rutas SSMS\n",
    "LOCAL_SERVER = 'localhost'\n",
    "LOCAL_DATABASE = 'dwh_case1'\n",
    "LOCAL_DRIVER = '{ODBC Driver 17 for SQL Server}'\n",
    "# Conexi√≥n a SQL Server Local\n",
    "local_conn_str = f\"DRIVER={LOCAL_DRIVER};SERVER={LOCAL_SERVER};DATABASE={LOCAL_DATABASE};Trusted_Connection=yes;TrustServerCertificate=yes\"\n",
    "\n",
    "#  Ruta de la carpeta donde est√°n las consutlas para modelo dimensional \n",
    "SQL_QUERIES_PATH = os.path.join(os.getcwd(), \"queries\")\n",
    "\n",
    "#  Obtener lista de archivos SQL\n",
    "sql_files = [f for f in os.listdir(SQL_QUERIES_PATH) if f.endswith(\".sql\")]\n",
    "\n",
    "# Verificar si hay consultas en la carpeta\n",
    "if not sql_files:\n",
    "    print(\" ERROR: No se encontraron archivos .sql en la carpeta.\")\n",
    "else:\n",
    "    print(f\" Encontrados {len(sql_files)} archivos SQL.\")\n",
    "\n",
    "#  Conectar a Azure SQL\n",
    "try:\n",
    "    print(\"1.Conectando a Azure SQL\")\n",
    "    conn_azure = pyodbc.connect(azure_conn_str)\n",
    "    cursor_azure = conn_azure.cursor()\n",
    "\n",
    "    print(\"2.Conectando a SQL Server Local\")\n",
    "    conn_local = pyodbc.connect(local_conn_str)\n",
    "    cursor_local = conn_local.cursor()\n",
    "\n",
    "    for sql_file in sql_files:\n",
    "        file_path = os.path.join(SQL_QUERIES_PATH, sql_file)\n",
    "\n",
    "        print(f\" Procesando archivo: {sql_file}\")\n",
    "\n",
    "        # Leer el contenido del archivo SQL\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            sql_query = file.read()\n",
    "\n",
    "        # Ejecutar consulta en Azure SQL\n",
    "        print(f\" Ejecutando consulta en Azure SQL para {sql_file}\")\n",
    "        df = pd.read_sql(sql_query, conn_azure)\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\" No hay datos para {sql_file}.No se crear√° la tabla en SQL Server Local.\")\n",
    "            continue\n",
    "\n",
    "        print(f\" Datos extra√≠dos: {df.shape[0]} filas.\")\n",
    "\n",
    "        # Convertir NaN a 0\n",
    "        df = df.fillna(0)\n",
    "\n",
    "        # Ajustar tipos de datos\n",
    "        for col in df.select_dtypes(include=['float64']).columns:\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "        for col in df.select_dtypes(include=['int64']).columns:\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "\n",
    "        # Nombre de la tabla local (sin extensi√≥n)\n",
    "        table_name = os.path.splitext(sql_file)[0]\n",
    "\n",
    "        # Eliminar tabla si ya existe\n",
    "        drop_table_sql = f\"DROP TABLE IF EXISTS {table_name}\"\n",
    "        cursor_local.execute(drop_table_sql)\n",
    "        conn_local.commit()\n",
    "\n",
    "        print(f\" Tabla {table_name} eliminada si exist√≠a.\")\n",
    "\n",
    "        # Crear la tabla con los tipos de datos ajustados\n",
    "        create_table_sql = f\"\"\"\n",
    "        CREATE TABLE {table_name} (\n",
    "            {', '.join([\n",
    "                f'[{col}] FLOAT' if df[col].dtype == np.float32 \n",
    "                else f'[{col}] INT' if df[col].dtype == np.int32 \n",
    "                else f'[{col}] NVARCHAR(255)' for col in df.columns\n",
    "            ])}\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor_local.execute(create_table_sql)\n",
    "        conn_local.commit()\n",
    "\n",
    "        print(f\"‚úÖ Tabla {table_name} creada en SQL Server Local.\")\n",
    "\n",
    "        # Insertar datos en la tabla\n",
    "        placeholders = ', '.join(['?' for _ in df.columns])\n",
    "        insert_sql = f\"INSERT INTO {table_name} VALUES ({placeholders})\"\n",
    "\n",
    "        cursor_local.fast_executemany = True\n",
    "        cursor_local.executemany(insert_sql, df.values.tolist())\n",
    "        conn_local.commit()\n",
    "\n",
    "        print(f\" {df.shape[0]} filas insertadas en {table_name}.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'conn_azure' in locals():\n",
    "        conn_azure.close()\n",
    "    if 'conn_local' in locals():\n",
    "        conn_local.close()\n",
    "\n",
    "print(\"\\n ¬°Proceso completado!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
